name: "bert"
pretrained_model: "bert-base-uncased"

learning_rate: 1e-4
adamw_beta1: 0.9
adamw_beta2: 0.999
weight_decay: 0.01
warmup_steps: 10000
num_train_epochs: 100
pad_to_max_length: True
max_seq_length: None
mlm_probability: 0.15
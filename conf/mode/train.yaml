name: "train"

do_train: True
do_eval: True
continue_training: False
overwrite_output_dir: False

#per_device_train_batch_size: 32
#per_device_eval_batch_size: 32
#learning_rate: 3e-5
#weight_decay: 0.1
#num_train_epochs: 50
#pad_to_max_length: True
#max_seq_length: None
#mlm_probability: 0.15

evaluation_strategy: "steps"
freeze_encoder: True # only applied if "architecture=seq"
eval_steps: 1000
save_steps: 2000
logging_steps: 1000
load_best_model_at_end: True
early_stopping: True
patience: 50

save_model: True

name: "mlm_inference"

inference_mode: "file" # "interactive" (enter sentence via UI) versus "file" (from file, e.g. test set)
input_path: "data/data/all_data_en/crisis_consolidated_humanitarian_filtered_lang_en_test.tsv" # path to file with inference input
output_path: "inference_output"